{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FifthStep(Padding).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMfRdII9e5DOtzoXOYGlHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeonJungHoon/NLP-/blob/main/FifthStep(Padding).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qkHTsL4B255",
        "outputId": "8ea1cfef-dd8c-4c05-b719-53b02d624735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5],\n",
            " [1, 8, 5],\n",
            " [1, 3, 5],\n",
            " [9, 2],\n",
            " [2, 4, 3, 2],\n",
            " [3, 2],\n",
            " [1, 4, 6],\n",
            " [1, 4, 6],\n",
            " [1, 4, 2],\n",
            " [7, 7, 3, 2, 10, 1, 11],\n",
            " [1, 12, 3, 13]]\n",
            "최대 길이 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from pprint import pprint\n",
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
        "pprint(encoded)\n",
        "\n",
        "max_len = max(len(item)for item in encoded)\n",
        "print(\"최대 길이 {}\".format(max_len))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in encoded:\n",
        "  while len(sentence) < max_len:\n",
        "    sentence.append(0)\n",
        "    \n",
        "padded_np = np.array(encoded)\n",
        "padded_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7qY0FO6C3su",
        "outputId": "c3182096-608b-4901-94d2-7952567c399a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0,  0,  0],\n",
              "       [ 3,  2,  0,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padding With Keras"
      ],
      "metadata": {
        "id": "1h8txikmDGv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
        "padded = pad_sequences(encoded)\n",
        "pprint(padded)\n",
        "\"\"\"\n",
        "Numpy로 패딩을 진행하였을 때와는 패딩 결과가 다른데 \n",
        "그 이유는 pad_sequences는 기본적으로 문서의 뒤에 0을 채우는 것이 아니라 \n",
        "앞에 0으로 채우기 때문입니다. \n",
        "뒤에 0을 채우고 싶다면 인자로 padding='post'를 주면됩니다.\n",
        "\"\"\"\n",
        "pad = pad_sequences(encoded, padding = 'post')\n",
        "pprint(pad)\n",
        "pad_test = pad_sequences(encoded, padding = 'post', maxlen = 3)\n",
        "pprint(pad_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TezYcV1HDFn0",
        "outputId": "8c60ea5b-986f-490f-d2ab-c831326fa04d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([[ 0,  0,  0,  0,  0,  1,  5],\n",
            "       [ 0,  0,  0,  0,  1,  8,  5],\n",
            "       [ 0,  0,  0,  0,  1,  3,  5],\n",
            "       [ 0,  0,  0,  0,  0,  9,  2],\n",
            "       [ 0,  0,  0,  2,  4,  3,  2],\n",
            "       [ 0,  0,  0,  0,  0,  3,  2],\n",
            "       [ 0,  0,  0,  0,  1,  4,  6],\n",
            "       [ 0,  0,  0,  0,  1,  4,  6],\n",
            "       [ 0,  0,  0,  0,  1,  4,  2],\n",
            "       [ 7,  7,  3,  2, 10,  1, 11],\n",
            "       [ 0,  0,  0,  1, 12,  3, 13]], dtype=int32)\n",
            "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
            "       [ 1,  8,  5,  0,  0,  0,  0],\n",
            "       [ 1,  3,  5,  0,  0,  0,  0],\n",
            "       [ 9,  2,  0,  0,  0,  0,  0],\n",
            "       [ 2,  4,  3,  2,  0,  0,  0],\n",
            "       [ 3,  2,  0,  0,  0,  0,  0],\n",
            "       [ 1,  4,  6,  0,  0,  0,  0],\n",
            "       [ 1,  4,  6,  0,  0,  0,  0],\n",
            "       [ 1,  4,  2,  0,  0,  0,  0],\n",
            "       [ 7,  7,  3,  2, 10,  1, 11],\n",
            "       [ 1, 12,  3, 13,  0,  0,  0]], dtype=int32)\n",
            "array([[ 1,  5,  0],\n",
            "       [ 1,  8,  5],\n",
            "       [ 1,  3,  5],\n",
            "       [ 9,  2,  0],\n",
            "       [ 4,  3,  2],\n",
            "       [ 3,  2,  0],\n",
            "       [ 1,  4,  6],\n",
            "       [ 1,  4,  6],\n",
            "       [ 1,  4,  2],\n",
            "       [10,  1, 11],\n",
            "       [12,  3, 13]], dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-Hot-Encoding"
      ],
      "metadata": {
        "id": "9OXvVJlSEhaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc70CpXYEj-X",
        "outputId": "929bb87c-ecf8-4fc3-e478-54c4d5ce38be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "tokens = okt.morphs(\"나는 자연어 처리를 배운다\")\n",
        "pprint(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsZxT7ebEohe",
        "outputId": "80cadf61-47bb-4b3e-c2a6-608a07933d49"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = {word:index for index, word in enumerate(tokens)}\n",
        "print(\"단어 집합: {}\".format(word_to_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9dYrNtuEzI3",
        "outputId": "946d6b1d-b292-4823-9c18-7639e5f299b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합: {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word, word_to_idx):\n",
        "  one_hot_vector = [0] * (len(word_to_idx))\n",
        "  index = word_to_idx[word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector\n",
        "\n",
        "one_hot_encoding('자연어', word_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn6q749EFAc2",
        "outputId": "303d9c16-82e2-40e1-f1cf-875e24500137"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-Hot-Encoding With Keras"
      ],
      "metadata": {
        "id": "XgqxHhKsGTnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tokenizer= Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "pprint(\"단어 집합: {}\".format(tokenizer.word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKWkr4HuGWQ4",
        "outputId": "e6226fc6-f4d3-4038-aad0-d7c68b90661e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"단어 집합: {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
        "pprint(encoded)\n",
        "\n",
        "one_hot = to_categorical(encoded)\n",
        "pprint(\"one-hot-encoding: {}\".format(one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw_j6DteGq6c",
        "outputId": "7808e0c7-6457-412b-cbf4-4e807796b4df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n",
            "('one-hot-encoding: [[0. 0. 1. 0. 0. 0. 0. 0.]\\n'\n",
            " ' [0. 0. 0. 0. 0. 1. 0. 0.]\\n'\n",
            " ' [0. 1. 0. 0. 0. 0. 0. 0.]\\n'\n",
            " ' [0. 0. 0. 0. 0. 0. 1. 0.]\\n'\n",
            " ' [0. 0. 0. 1. 0. 0. 0. 0.]\\n'\n",
            " ' [0. 0. 0. 0. 0. 0. 0. 1.]]')\n"
          ]
        }
      ]
    }
  ]
}